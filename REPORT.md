# Отчет по тестовому заданию: AI-ассистент для анализа данных

## 1. Описание подхода к решению задачи

Ключевым ограничением задачи была невозможность прямой загрузки всего набора данных в языковую модель. Это требование полностью соответствует реальным сценариям, где данные могут быть конфиденциальными, слишком большими или динамически обновляться.

Выбранный подход — **создание LLM-агента с доступом к инструментам**. В этой архитектуре языковая модель (LLM) выступает не как база данных, а как "мозг", принимающий решения. Ей предоставляется не сам датасет, а только его метаданные (названия колонок) и инструмент для анализа — интерпретатор Python с библиотекой `pandas`.

Процесс работы системы выглядит так:
1.  Пользователь вводит вопрос на естественном языке через интерфейс командной строки (CLI).
2.  LLM-агент получает вопрос и информацию о доступных колонках в DataFrame.
3.  Вместо того чтобы пытаться ответить самостоятельно, LLM **генерирует Python-код**, необходимый для извлечения ответа из DataFrame.
4.  Сгенерированный код безопасно выполняется в окружении.
5.  Результат выполнения кода (например, число или таблица) возвращается LLM.
6.  LLM анализирует полученный результат и формулирует окончательный, человекочитаемый ответ на русском языке.

**Стек технологий:**
*   **Язык:** Python 3.10+
*   **LLM Framework:** LangChain (для создания и управления агентом).
*   **LLM:** Google Gemini 2.5 Flash с Google Gemini 2.0 Flash (через `langchain-google-genai`).
*   **Анализ данных:** Pandas.
*   **CLI:** Click.

## 2. Оценка эффективности и точности системы

### Что сработало хорошо

*   **Точность вычислений:** После первоначальной отладки агент генерирует корректный `pandas`-код для широкого спектра задач: от простых агрегаций (`mean`, `count`) до более сложных, таких как расчет корреляции, группировка с сортировкой (`groupby`, `nlargest`) и фильтрация по нескольким условиям.
*   **Самокоррекция:** В ходе тестирования был выявлен примечательный случай. При запросе о среднем рейтинге агент сначала сгенерировал код с несуществующим именем колонки (`Revenue_USD`), что привело к ошибке `KeyError`. Агент смог распознать эту ошибку, самостоятельно запросил список актуальных колонок (`df.columns`) и в следующей итерации использовал правильное имя (`Earnings_USD`), успешно решив задачу. Это демонстрирует высокую степень "интеллекта" и надежности архитектуры.
*   **Преодоление "галлюцинаций":** Изначально агент на некоторые запросы игнорировал предоставленный DataFrame и генерировал собственный, случайный набор данных. Эта критическая проблема была решена с помощью "заземления" (grounding) модели через параметр `prefix` в системном промпте, который жестко предписывает модели использовать только существующий `df`.

### Что сработало хуже (ограничения и точки роста)

*   **Хрупкость парсинга:** В одном из тестов на сложный вопрос агент сгенерировал корректные вычисления, но его финальный "мыслительный процесс" не соответствовал формату, ожидаемому парсером LangChain, что привело к ошибке `Invalid Format`. Хотя система в итоге восстановилась, это указывает на потенциальную нестабильность.
*   **Ограничения API:** При выполнении нескольких запросов подряд система столкнулась с ошибкой `429 ResourceExhausted`. Это ограничение бесплатного уровня Gemini API. В реальном продукте это потребовало бы перехода на платный тариф и/или внедрения механизмов управления очередью запросов и экспоненциальной задержки (exponential backoff).
*   **Чувствительность к формулировкам:** Агент может неверно интерпретировать синонимы в данных. Например, в данных проекты были помечены как `'Fixed'`, а в запросе использовалось `'Fixed-Price'`. В данном случае модель справилась, но это остается потенциальной точкой отказа, которую в продакшене можно решать предварительной очисткой данных или более сложными промптами.

## 3. Критерии оценки качества решения

Качество прототипа оценивалось по следующим критериям:

1.  **Корректность ответа:** Является ли финальный числовой или текстовый ответ правильным?
    *   *Оценка: Высокая.* После решения проблемы с галлюцинацией все ответы, которые система смогла дать, были математически верны.

2.  **Надежность и обработка ошибок:** Как система ведет себя в нештатных ситуациях?
    *   *Оценка: Средняя.* Система отлично справляется с ошибками выполнения кода (например, `KeyError`), но уязвима для ошибок парсинга ответа LLM и внешних ограничений (API-лимиты).

3.  **Качество кода и архитектуры:** Код должен быть читаемым, модульным и следовать общепринятым практикам.
    *   *Оценка: Высокая.* Код разбит на логические функции (`create_agent`, `cli`), использует современные инструменты (`click`, `dotenv`) и следует принципам чистоты и читаемости. Архитектура агента является расширяемой.

4.  **Интерпретируемость "мыслей" агента:** Понятно ли из логов (`verbose=True`), как агент пришел к своему выводу?
    *   *Оценка: Высокая.* Логи `Thought: ... Action: ...` позволяют полностью отследить цепочку рассуждений, что является бесценным для отладки и оценки доверия к системе.